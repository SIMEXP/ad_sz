{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf8e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from datetime import datetime # is this needed?\n",
    "from functools import reduce\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9911c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to files\n",
    "adni_data = Path(\"__file__\").resolve().parents[1] / 'data' / 'adni_spreadsheet.csv'\n",
    "tau_data = Path(\"__file__\").resolve().parents[1] / 'data' / 'UCBERKELEYAV1451_04_26_22.csv'\n",
    "other_biomarker_data = Path(\"__file__\").resolve().parents[1] / 'data' / 'ADNIMERGE.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347419b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = get_baselines(adni_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "25145333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load biomarker files\n",
    "tau_df = load_biomarker_df(tau_data)\n",
    "other_biomarkers_df = load_biomarker_df(other_biomarker_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one df per biomarker with closest result within a one year window of participant baseline\n",
    "tau = get_biomarker(tau_df, baseline_df, 'META_TEMPORAL_SUVR')\n",
    "abeta = get_biomarker(other_biomarkers_df, baseline_df, 'ABETA')\n",
    "ptau = get_biomarker(other_biomarkers_df, baseline_df, 'PTAU')\n",
    "av45 = get_biomarker(other_biomarkers_df, baseline_df, 'AV45')\n",
    "fbb = get_biomarker(other_biomarkers_df, baseline_df, 'FBB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "e7ff375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of dataframes (baseline data and all individual biomarkers)\n",
    "\n",
    "data_frames = [baseline_df, tau, abeta, ptau, av45, fbb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "833b60e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>session</th>\n",
       "      <th>date_lower</th>\n",
       "      <th>date_upper</th>\n",
       "      <th>META_TEMPORAL_SUVR</th>\n",
       "      <th>META_TEMPORAL_SUVR_EXAMDATE</th>\n",
       "      <th>ABETA</th>\n",
       "      <th>ABETA_EXAMDATE</th>\n",
       "      <th>PTAU</th>\n",
       "      <th>PTAU_EXAMDATE</th>\n",
       "      <th>AV45</th>\n",
       "      <th>AV45_EXAMDATE</th>\n",
       "      <th>FBB</th>\n",
       "      <th>FBB_EXAMDATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>011_S_0021</td>\n",
       "      <td>ADNI 3</td>\n",
       "      <td>F</td>\n",
       "      <td>CN</td>\n",
       "      <td>ADNI3 Initial Visit-Cont Pt</td>\n",
       "      <td>1/25/2018</td>\n",
       "      <td>84.9</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>1.2700</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0376</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>023_S_0031</td>\n",
       "      <td>ADNI 3</td>\n",
       "      <td>F</td>\n",
       "      <td>CN</td>\n",
       "      <td>ADNI3 Initial Visit-Cont Pt</td>\n",
       "      <td>4/17/2018</td>\n",
       "      <td>90.3</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>2019-04-17</td>\n",
       "      <td>1.1098</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>1.5034</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>067_S_0056</td>\n",
       "      <td>ADNI 3</td>\n",
       "      <td>F</td>\n",
       "      <td>CN</td>\n",
       "      <td>ADNI3 Year 1 Visit</td>\n",
       "      <td>1/10/2019</td>\n",
       "      <td>82.8</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>1.2115</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>067_S_0059</td>\n",
       "      <td>ADNI 3</td>\n",
       "      <td>F</td>\n",
       "      <td>CN</td>\n",
       "      <td>ADNI3 Initial Visit-Cont Pt</td>\n",
       "      <td>12/20/2017</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>1.2017</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>100_S_0069</td>\n",
       "      <td>ADNI 2</td>\n",
       "      <td>M</td>\n",
       "      <td>CN</td>\n",
       "      <td>ADNI2 Year 2 Visit</td>\n",
       "      <td>1/28/2014</td>\n",
       "      <td>81.1</td>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID   Phase Sex Research Group                        Visit  \\\n",
       "RID                                                                       \n",
       "21   011_S_0021  ADNI 3   F             CN  ADNI3 Initial Visit-Cont Pt   \n",
       "31   023_S_0031  ADNI 3   F             CN  ADNI3 Initial Visit-Cont Pt   \n",
       "56   067_S_0056  ADNI 3   F             CN           ADNI3 Year 1 Visit   \n",
       "59   067_S_0059  ADNI 3   F             CN  ADNI3 Initial Visit-Cont Pt   \n",
       "69   100_S_0069  ADNI 2   M             CN           ADNI2 Year 2 Visit   \n",
       "\n",
       "     Study Date   Age    session date_lower date_upper  META_TEMPORAL_SUVR  \\\n",
       "RID                                                                          \n",
       "21    1/25/2018  84.9 2018-01-25 2017-01-25 2019-01-25              1.2700   \n",
       "31    4/17/2018  90.3 2018-04-17 2017-04-17 2019-04-17              1.1098   \n",
       "56    1/10/2019  82.8 2019-01-10 2018-01-10 2020-01-10              1.2115   \n",
       "59   12/20/2017  83.0 2017-12-20 2016-12-20 2018-12-20              1.2017   \n",
       "69    1/28/2014  81.1 2014-01-28 2013-01-28 2015-01-28                 NaN   \n",
       "\n",
       "    META_TEMPORAL_SUVR_EXAMDATE ABETA ABETA_EXAMDATE PTAU PTAU_EXAMDATE  \\\n",
       "RID                                                                       \n",
       "21                   2018-02-02   NaN            NaT  NaN           NaT   \n",
       "31                   2018-04-24   NaN     2016-01-26  NaN    2016-01-26   \n",
       "56                   2019-01-10   NaN     2010-12-10  NaN    2010-12-10   \n",
       "59                   2017-12-12   NaN     2010-12-10  NaN    2010-12-10   \n",
       "69                   2018-04-03   NaN            NaT  NaN           NaT   \n",
       "\n",
       "       AV45 AV45_EXAMDATE  FBB FBB_EXAMDATE  \n",
       "RID                                          \n",
       "21   1.0376    2017-11-27  NaN          NaT  \n",
       "31   1.5034    2018-04-17  NaN          NaT  \n",
       "56   0.9688    2019-12-03  NaN          NaT  \n",
       "59   0.9898    2017-12-12  NaN          NaT  \n",
       "69   0.9592    2014-01-28  NaN          NaT  "
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframes\n",
    "\n",
    "master_biomarkers = reduce(lambda left, right:\n",
    "             pd.merge_asof(left, right, left_index=True, right_index=True),\n",
    "             data_frames)\n",
    "master_biomarkers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "7d439686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "master_biomarkers.to_csv(Path(\"__file__\").resolve().parents[1] / 'data' / 'master_biomarkers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27540f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c6ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "c5dade13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biomarker(biomarker_df, baseline_df, biomarker):\n",
    "    \n",
    "    find_nearest_biomarker = match_baselines_biomarker(biomarker_df, baseline_df, biomarker)\n",
    "    window_checked = check_visit_window(find_nearest_biomarker, baseline_df, biomarker)\n",
    "    \n",
    "    return (window_checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e56b0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baselines(file):\n",
    "    # load baseline phenotypic data\n",
    "    pheno = pd.read_csv(file, index_col=0, header=0)\n",
    "\n",
    "    # keep only the variables of interest\n",
    "    pheno = pheno.filter(['Subject ID','Phase','Sex','Research Group', 'Visit','Study Date','Age'], axis=1)\n",
    "\n",
    "    # convert 'study date' to 'session' in datetime format, to match other spreadsheets\n",
    "    pheno['session'] = pd.to_datetime(pheno['Study Date'])\n",
    "    \n",
    "    # pull out only the subject id and asign it to the index\n",
    "    pheno_subj = []\n",
    "    for i in pheno['Subject ID']:\n",
    "        subj = i.split('_')[2].lstrip(\"0\") # remove leading zeros since it won't match ADNI IDs\n",
    "        pheno_subj.append(subj)\n",
    "    \n",
    "    pheno.index = pheno_subj\n",
    "    pheno.rename_axis('RID',inplace=True)\n",
    "    pheno.index = pheno.index.astype('int64')\n",
    "    \n",
    "    # separate patients and controls, because (in theory) we can use any control visit as baseline, but\n",
    "    # for patients we want their actual baseline data\n",
    "    patient_diagnoses = ['AD', 'EMCI', 'LMCI', 'MCI', 'SMC']\n",
    "    patient_df = pheno[pheno['Research Group'].isin(patient_diagnoses)] # df of patient diagnoses\n",
    "\n",
    "    control_df = pheno.loc[pheno['Research Group'] == 'CN'] # df of control diagnoses\n",
    "\n",
    "    # I think these visits are acceptable as baseline data, i.e. actual baseline +/-3 months, excluding\n",
    "    # any initial visits where patient continued from a previous phase\n",
    "    bl_visits = ['ADNI Screening','ADNI2 Month 3 MRI-New Pt', 'ADNI2 Screening MRI-New Pt', \n",
    "                   'ADNIGO Month 3 MRI','ADNIGO Screening MRI']\n",
    "\n",
    "    patient_df_bl = patient_df[patient_df['Visit'].isin(bl_visits)]\n",
    "    \n",
    "    # rejoin the patients to the controls\n",
    "    new_df = pd.concat([control_df,patient_df_bl])\n",
    "    \n",
    "    # select the earliest visit available for each participant\n",
    "    new_df.sort_values(['Subject ID', 'Age'], inplace=True) # sort by age\n",
    "    baseline_df = new_df[~new_df.duplicated(['Subject ID'], keep='first')] # select the first row\n",
    "    \n",
    "    # sort df by index\n",
    "    baseline_df.sort_values(by='RID', inplace=True)\n",
    "    \n",
    "    # calculate window for acceptable biomarker data, currently +- 12months\n",
    "    baseline_df.loc[:,('date_lower')] = baseline_df.loc[:,('session')] - pd.DateOffset(months=12)\n",
    "    baseline_df.loc[:,('date_upper')] = baseline_df.loc[:,('session')] + pd.DateOffset(months=12)\n",
    "\n",
    "    return (baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "fbbf856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_biomarker_df(biomarker_data):\n",
    "\n",
    "    # load data\n",
    "    biomarker_df = pd.read_csv(biomarker_data, index_col=0, header=0, low_memory=False)\n",
    "\n",
    "    # convert examdate to datetime\n",
    "    biomarker_df['EXAMDATE'] = pd.to_datetime(biomarker_df['EXAMDATE'])\n",
    "\n",
    "    # sort df by index and date\n",
    "    biomarker_df.sort_values(by=['RID', 'EXAMDATE'],inplace=True)\n",
    "\n",
    "    # create column from index (useful for later functions)\n",
    "    biomarker_df['RID'] = biomarker_df.index\n",
    "    \n",
    "    return (biomarker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "7794450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_baselines_biomarker(biomarker_df, baseline_df, biomarker):\n",
    "    \n",
    "    df = pd.DataFrame(columns=['RID',biomarker,biomarker+'_EXAMDATE']) #create df\n",
    "    common_ids = biomarker_df.index.intersection(baseline_df.index) #find ids common to the biomarker and baseline dfs\n",
    "    biomarker_df = biomarker_df.set_index('EXAMDATE') #reindex, needed to use 'nearest'method\n",
    "\n",
    "    for rid in common_ids:\n",
    "        participant_df = biomarker_df[(biomarker_df['RID'] == rid)] #create df of all participants results\n",
    "        baseline = baseline_df.loc[rid] #create df of participants baseline data\n",
    "        session = baseline['session'] #participant's baseline date\n",
    "\n",
    "        participant_df = participant_df.dropna(subset=[biomarker])\n",
    "\n",
    "        if participant_df.empty:\n",
    "            pass\n",
    "        else:\n",
    "\n",
    "            idx_nearest = participant_df.index.get_loc(session, method='nearest') #find the closest test date to session\n",
    "            nearest_date = participant_df.index[idx_nearest]\n",
    "            nearest_result = participant_df[biomarker][idx_nearest] #find the biomarker result associated with closest date\n",
    "\n",
    "            df.loc[len(df)] = [rid,nearest_result,nearest_date] #add to df\n",
    "    df = df.set_index('RID')        \n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "9f7b302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_visit_window(biomarker_df, baseline_df, biomarker):\n",
    "    \n",
    "    '''\n",
    "    Join closest biomarkers to baseline info, check if the result was collected on a date within the baseline\n",
    "    window, and if not replace with NaN. Drop unwanted columns and return biomarker info again, ready to merge.\n",
    "    '''\n",
    "    \n",
    "    # create new df, merging biomarker data into baseline df\n",
    "    baseline_bio = baseline_df.join(biomarker_df)\n",
    "    \n",
    "    # create mask of date range, between lower and upper acceptable dates\n",
    "    mask_date_range = (baseline_bio[biomarker+'_EXAMDATE'] > baseline_bio['date_lower']) & (baseline_bio[biomarker+'_EXAMDATE'] < baseline_bio['date_upper'])\n",
    "    \n",
    "    # fill values collected outside date range with NaN\n",
    "    baseline_bio[biomarker][~mask_date_range] = np.nan\n",
    "    \n",
    "    cols_to_drop = ['Subject ID',\n",
    "     'Phase',\n",
    "     'Sex',\n",
    "     'Research Group',\n",
    "     'Visit',\n",
    "     'Study Date',\n",
    "     'Age',\n",
    "     'session',\n",
    "     'date_lower',\n",
    "     'date_upper']\n",
    "    \n",
    "    baseline_bio = baseline_bio.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    return (baseline_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68e937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1a750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44c511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "99b631af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeec93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c2b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93009b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9f245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464d0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15ebcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0576b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede16952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1e884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d00d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ce9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc6f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcebbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4016c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aab466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3179aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716f27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54efc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f23747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5ed6b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_match_baseline_tau(baseline_df, tau_df):\n",
    "    \n",
    "    '''\n",
    "    Group subjects in the tau df, look them up in the baseline df, and if they match return the tau\n",
    "    value closest to the session date in baseline. Return a list of dfs, one per subject, merge into\n",
    "    baseline df, and then keep only those within a 12 month window. This seems a silly and expensive way \n",
    "    to do this! But, I ran into all sorts of problems with the datetime format and this is the only way \n",
    "    I figured it out...\n",
    "    '''\n",
    "    \n",
    "    tau_dfs_list = []\n",
    "    for tau_id, group in tau_df.groupby(level='RID'):\n",
    "        for baseline_id, session in zip(baseline_df.index, baseline_df.session):\n",
    "            if tau_id == baseline_id:\n",
    "                participant_df = group\n",
    "                participant_df.set_index('EXAMDATE', inplace=True)\n",
    "                participant_tau = pd.DataFrame(participant_df['META_TEMPORAL_SUVR'][participant_df.index[[participant_df.index.get_loc(session, method='nearest')]]])\n",
    "                participant_tau['EXAMDATE'] = participant_tau.index\n",
    "                participant_tau.index = [baseline_id]\n",
    "                participant_tau.rename_axis('RID',inplace=True)\n",
    "                tau_dfs_list.append(participant_tau)\n",
    "                \n",
    "    # concatenate individual tau dfs\n",
    "    master_tau = pd.concat(tau_dfs_list)\n",
    "    \n",
    "    # create new df and merge tau data into baseline df\n",
    "    baseline_tau = baseline_df.join(master_tau)\n",
    "    \n",
    "    # create mask of date range, between lower and upper acceptable dates\n",
    "    mask_date_range = (baseline_tau.EXAMDATE > baseline_tau.date_lower) & (baseline_tau.EXAMDATE < baseline_tau.date_upper)\n",
    "    \n",
    "    # fill values collected outside date range with NaN\n",
    "    baseline_tau['META_TEMPORAL_SUVR'][~mask_date_range] = np.nan\n",
    "    \n",
    "    # rename EXAMDATE column - decide later whether keeping this, but useful for sanity check\n",
    "    baseline_tau.rename(columns={\"EXAMDATE\": \"tau_EXAMDATE\"}, inplace=True)\n",
    "          \n",
    "    return (baseline_tau)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4681931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_get_tau(file):\n",
    "    # load tau data\n",
    "    tau_df = pd.read_csv(tau_data, index_col=0, header=0, low_memory=False)\n",
    "\n",
    "    # keep only relevant columns\n",
    "    tau_df = tau_df.filter(['EXAMDATE','META_TEMPORAL_SUVR'], axis=1)\n",
    "\n",
    "    # convert to datetime\n",
    "    tau_df['EXAMDATE'] = pd.to_datetime(tau_df['EXAMDATE'])\n",
    "\n",
    "    # sort tau df by index and date. Also throws an error\n",
    "    tau_df.sort_values(by=['RID', 'EXAMDATE'],inplace=True)\n",
    "    \n",
    "    # create column from index (useful for later functions)\n",
    "    tau_df['RID'] = tau_df.index\n",
    "    \n",
    "    return (tau_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "65f5fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_match_baselines_biomarker(biomarker_df, baseline_df, biomarker):\n",
    "    \n",
    "    df = pd.DataFrame(columns=['RID',biomarker,biomarker+'_EXAMDATE']) #create df\n",
    "    common_ids = biomarker_df.index.intersection(baseline_df.index) #find ids common to the biomarker and baseline dfs\n",
    "    biomarker_df = biomarker_df[biomarker+'_EXAMDATE', biomarker]\n",
    "    biomarker_df = biomarker_df.set_index('EXAMDATE') #reindex, needed to use 'nearest'method\n",
    "\n",
    "    for rid in common_ids:\n",
    "        participant_df = biomarker_df[(biomarker_df['RID'] == rid)] #create df of all participants results\n",
    "        baseline = baseline_df.loc[rid] #create df of participants baseline data\n",
    "        session = baseline['session'] #participant's baseline date\n",
    "\n",
    "        idx_nearest = participant_df.index.get_loc(session, method='nearest') #find the closest test date to session\n",
    "        nearest_date = participant_df.index[idx_nearest]\n",
    "        nearest_result = participant_df[biomarker][idx_nearest] #find the biomarker result associated with closest date\n",
    "\n",
    "        df.loc[len(df)] = [rid,nearest_result,nearest_date] #add to df\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_merge_biomarkers(biomarker_df, baseline_df, biomarker):\n",
    "    \n",
    "    # create new df, merging biomarker data into baseline df\n",
    "    baseline_bio = baseline_df.join(biomarker_df)\n",
    "    \n",
    "    # create mask of date range, between lower and upper acceptable dates\n",
    "    mask_date_range = (baseline_bio[biomarker+'_EXAMDATE'] > baseline_bio['date_lower']) & (baseline_bio[biomarker+'_EXAMDATE'] < baseline_bio['date_upper'])\n",
    "    \n",
    "    # fill values collected outside date range with NaN\n",
    "    baseline_bio[biomarker][~mask_date_range] = np.nan\n",
    "    \n",
    "    return (baseline_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5dec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
